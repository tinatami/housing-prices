{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "import ppscore as pps\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMClassifier, plot_importance as plot_importance_lgbm\n",
    "from xgboost import XGBClassifier, XGBRegressor, plot_importance as plot_importance_xgb\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = (train_data.isnull().sum())\n",
    "print(\"Missing values per column:\\n\", missing_values[missing_values > 0])\n",
    "print(\"\\n Percentage missing values per column:\\n\", missing_values[missing_values > 0]/train_data.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 99.5% of PoolQC (pool quality) is missing (aka no pool)\n",
    "-> there is PoolArea column which will say 0 if no pool\n",
    "- 93.8% of Alley (type of alley access) is missing (aka no alley access)\n",
    "- 96.3% of MiscFeature (miscellaneous feature not covered in other categories) is missing\n",
    "-> there is MiscVal feature that will say 0 if no misc feature\n",
    "- 80.8% of Fence (fence quality) is missing (aka no fence)\n",
    "- 47.3% of FireplaceQu (fireplace quality) is missing (aka no fireplace) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for each column\n",
    "for column in train_data.columns:\n",
    "    print(\"Column: {} \\n{} \\n\".format(column, train_data[column].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values in each column\n",
    "unique_cols = {}\n",
    "\n",
    "for column in train_data.columns:\n",
    "    unique_cols[column] = len(train_data[column].unique())\n",
    "\n",
    "for x in sorted(unique_cols.items(), key=operator.itemgetter(1)): \n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['SalePrice', 'Id'], axis=1).hist(figsize=(18,18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = train_data.corr()\n",
    "sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That was a lot, only top 10:\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "top_corr = train_data[corr.SalePrice.sort_values(ascending=False)[:10].index].corr()\n",
    "sns.heatmap(top_corr, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values in each top 10 column\n",
    "top10_cols = ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt']\n",
    "unique_cols = {}\n",
    "\n",
    "for column in top10_cols:\n",
    "    unique_cols[column] = len(train_data[column].unique())\n",
    "\n",
    "for x in sorted(unique_cols.items(), key=operator.itemgetter(1)): \n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = (train_data[top10_cols].isnull().sum())\n",
    "print(\"Missing values per column:\\n\", missing_values[missing_values > 0])\n",
    "print(\"\\n Percentage missing values per column:\\n\", missing_values[missing_values > 0]/train_data.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So no values are missing in the top 10 columns. \n",
    "\n",
    "But: (GarageCars, GarageArea) and (TotalBsmtSF, 1stFlrSF) and (TotRmsAbvGrd, 1stFlrSF) are highly correlated. So **GarageCars, TotRmsAbvGrd and TotalBsmtSF will be excluded**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining columns (features) that are categorical\n",
    "remaining_df = train_data.drop([\"GarageArea\", \"TotRmsAbvGrd\", \"TotalBsmtSF\", \"Id\"], axis=1)\n",
    "remaining_cols_cat = remaining_df.select_dtypes(include='object').columns\n",
    "\n",
    "# Value counts for each column with categorical value\n",
    "for column in remaining_cols_cat:\n",
    "    print(\"Column: {} \\n{} \\n\".format(column, remaining_df[column].value_counts()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilities** has only 1 entry where its value is NoSeWa, everything else is AllPub. Kind of the same holds for **Condition2, LandSlope, RoofMatl, GarageCond, GarageQual, Functional, Electrical, Heating, BsmtCond** so they will be exluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 99.5% of PoolQC (pool quality) is missing (aka no pool)\n",
    "-> there is PoolArea column which will say 0 if no pool\n",
    "- 93.8% of Alley (type of alley access) is missing (aka no alley access) -> **turn it into yes/no**\n",
    "- 96.3% of MiscFeature (miscellaneous feature not covered in other categories) is missing\n",
    "-> there is MiscVal feature that will say 0 if no misc feature\n",
    "- 80.8% of Fence (fence quality) is missing (aka no fence) -> **turn it into yes/no**\n",
    "- 47.3% of FireplaceQu (fireplace quality) is missing (aka no fireplace) -> **turn it into yes/no**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data.SalePrice\n",
    "train_data_sub = train_data.drop([\"SalePrice\", \"GarageCars\", \"TotRmsAbvGrd\", \"TotalBsmtSF\", \n",
    "                                \"Id\", \"Utilities\", \"Condition2\", \"LandSlope\", \n",
    "                                \"RoofMatl\", \"GarageCond\", \"GarageQual\", \"Functional\", \n",
    "                                \"Electrical\", \"Heating\", \"BsmtCond\"], \n",
    "                               axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Features that will be one-hot encoded:\n",
    "# one_hot = [\n",
    "#             'MSZoning', 'LandContour', 'LotConfig', 'Neighborhood', \n",
    "#             'Condition1', 'BldgType',\n",
    "#             'HouseStyle', 'RoofStyle', 'Exterior1st', \n",
    "#             'Exterior2nd', 'MasVnrType', 'Foundation', \n",
    "#             'GarageType', 'MiscFeature', \n",
    "#             'SaleType', 'SaleCondition'\n",
    "#             ]\n",
    "\n",
    "# # Features that will be label encoded:\n",
    "# label_encode = [\n",
    "#                 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual',\n",
    "#                 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual',\n",
    "#                 'FireplaceQu', 'PoolQC', 'Fence', 'Street', 'Alley',\n",
    "#                 'GarageFinish', 'MoSold', 'YrSold', 'PavedDrive', \n",
    "#                 'CentralAir', 'LotShape', 'MSSubClass', \n",
    "#                 ]\n",
    "\n",
    "# # Features that will stay numerical\n",
    "# num = [\n",
    "#         'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "#         '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
    "#         'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
    "#         'Fireplaces', 'GarageYrBlt', 'YearBuilt', 'YearRemodAdd',\n",
    "#         'OverallQual'\n",
    "#         ]\n",
    "\n",
    "# Things that will be turned into 1/0\n",
    "presence = ['MiscVal', 'PoolArea', 'ScreenPorch', '3SsnPorch', 'EnclosedPorch', 'OpenPorchSF', 'WoodDeckSF', 'GarageArea']\n",
    "\n",
    "# Columns where NaN means the described feature is not present\n",
    "na = ['Alley', 'BsmtQual', 'BsmtFinType1', 'BsmtFinType2', 'BsmtExposure', 'FireplaceQu', 'GarageType', 'GarageFinish', 'PoolQC', 'Fence', 'MiscFeature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn columns into present-or-not columns\n",
    "for column in presence:\n",
    "    train_data_sub.loc[train_data_sub[column] > 0, 'Presence'+column] = 1\n",
    "    train_data_sub.loc[train_data_sub[column] == 0, 'Presence'+column] = 0\n",
    "\n",
    "# Fill columns where NaN means the described feature is not present\n",
    "for x in na:\n",
    "    train_data_sub[na] = train_data_sub[na].fillna(\"Not present\")\n",
    "\n",
    "    \n",
    "# Drop columns that are now not needed anymore\n",
    "train_data_sub = train_data_sub.drop(presence, axis=1)\n",
    "cat_columns = train_data_sub.select_dtypes(include='object').columns\n",
    "num_columns = train_data_sub.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other ideas:\n",
    "    - Count total number of bathrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Pipelines and hyper parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "num_transformer_1 = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy='mean')),\n",
    "                                    ('scale', MinMaxScaler())\n",
    "                                    ])\n",
    "num_transformer_2 = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('scale', MinMaxScaler())\n",
    "                                    ])\n",
    "\n",
    "# Preprocessing for categorical one_hot data\n",
    "cat_transformer_1 = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                    ])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "data_transformer_1 = ColumnTransformer(transformers=[\n",
    "                                                        ('num', num_transformer_1, num_columns),\n",
    "                                                        ('cat', cat_oh_transformer_1, cat_columns)\n",
    "                                                    ])\n",
    "data_transformer_2 = ColumnTransformer(transformers=[\n",
    "                                                        ('num', num_transformer_2, num_columns),\n",
    "                                                        ('cat', cat_oh_transformer_1, cat_columns)\n",
    "                                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(data, target):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(data, target, test_size=0.10, random_state=1)\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocess', data_transformer_1), \n",
    "                               ('model', SVR())\n",
    "                              ]) \n",
    "\n",
    "    param_grid = [{ 'preprocess': [data_transformer_1, data_transformer_2],\n",
    "                    'model': [RandomForestRegressor()],\n",
    "                    #'model__criterion': [\"absolute_error\"],\n",
    "                    'model__n_estimators': np.arange(10, 100, 10),\n",
    "                    'model__max_depth': np.arange(3, 20, 1),\n",
    "                    'model__max_features': [None, \"sqrt\", \"log2\"]\n",
    "                 },\n",
    "                 {  'preprocess': [data_transformer_1, data_transformer_2],\n",
    "                    'model': [Lasso()],\n",
    "                    'model__alpha': np.arange(0, 200, 5)\n",
    "                 },\n",
    "                 {  'preprocess': [data_transformer_1, data_transformer_2],\n",
    "                    'model': [XGBRegressor()],\n",
    "                    'model__n_estimators': [int(x) for x in np.linspace(3, 15, num=10)],\n",
    "                    'model__eta': np.linspace(0.1, 0.9), # learning rate\n",
    "                    'model__max_depth': [int(x) for x in np.linspace(2, 7, num=5)],\n",
    "                    'model__gamma': np.linspace(0.1, 1), # min loss reduction required to make further partition on leaf node of tree\n",
    "                    'model__lambda': np.linspace(0.1, 1) # L2 regularization term on weight\n",
    "                 }]\n",
    "                \n",
    "    best_parameters = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, \n",
    "                                         cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1,\n",
    "                                         random_state=1)\n",
    "\n",
    "    _ = best_parameters.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best data pipeline: {} \\n\".format(best_parameters.best_estimator_[0]))\n",
    "    print(\"Best regressor: {} \\n\".format(best_parameters.best_estimator_[1]))\n",
    "    print(\"Best mean absolute error on training set: {} \\n\".format(abs(best_parameters.best_score_)))\n",
    "    \n",
    "    return X_train, X_valid, y_train, y_valid, best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(best_parameters, X_valid, y_valid):\n",
    "    predictions = best_parameters.best_estimator_.predict(X_valid)\n",
    "    result = mean_absolute_error(y_valid, predictions)\n",
    "    print(\"Mean absolute error on validation set: {}\".format(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid, best_parameters = find_best_model(train_data_sub, target)\n",
    "\n",
    "valid_set_results = evaluate_model(best_parameters, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Predicting target for test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare test data same way as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused features\n",
    "test_data_sub = test_data.drop([\"GarageCars\", \"TotRmsAbvGrd\", \"TotalBsmtSF\", \n",
    "                                \"Id\", \"Utilities\", \"Condition2\", \"LandSlope\", \n",
    "                                \"RoofMatl\", \"GarageCond\", \"GarageQual\", \"Functional\", \n",
    "                                \"Electrical\", \"Heating\", \"BsmtCond\"], \n",
    "                               axis=1)\n",
    "\n",
    "# Turn columns into present-or-not columns\n",
    "for column in presence:\n",
    "    test_data_sub.loc[test_data_sub[column] > 0, 'Presence'+column] = 1\n",
    "    test_data_sub.loc[test_data_sub[column] == 0, 'Presence'+column] = 0\n",
    "\n",
    "# Fill columns where NaN means the described feature is not present\n",
    "for x in na:\n",
    "    test_data_sub[na] = test_data_sub[na].fillna(\"Not present\")\n",
    "\n",
    "    \n",
    "# Drop columns that are now not needed anymore\n",
    "test_data_sub = test_data_sub.drop(presence, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying our best model's pipeline and parameters on test set\n",
    "test_predictions = best_parameters.best_estimator_.predict(test_data_sub)\n",
    "\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions file that will be submitted\n",
    "output = pd.DataFrame({'Id': test_data.Id, 'SalePrice': test_predictions})\n",
    "output.to_csv('housing-prices-submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
